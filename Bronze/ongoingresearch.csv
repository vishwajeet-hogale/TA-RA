Link,Abstract,Led-By,Co-Led-By
https://www.khoury.northeastern.edu/research_projects/eager-wireless-sensing-of-speech-kinematics-and-acoustics-for-remediation/,"Speech is complex and intricate, requiring coordination of numerous muscle groups and physiological systems. Approximately 2% of Americans have imprecise speech due to mislearning during development (articulation disorder) or neuromotor conditions. This project aims to develop a Lingual-Kinematic and Acoustic sensor technology (LinKa) that is lightweight, low-cost, wireless, and easy to deploy both clinically and at home for speech remediation. LinKa will leverage the sensing capabilities of the Tongue Drive System (TDS) and expertise in spoken interaction technologies for individuals with speech impairment, as well as machine learning and multimodal data fusion, to develop a prototype clinically viable tool for enhancing speech clarity by coupling lingual-kinematic and acoustic data. The system will be evaluated on six individuals with neuromotor speech impairment and six healthy age-matched controls.",Rupal Patel,Yun Raymond Fu
https://www.khoury.northeastern.edu/research_projects/wehe-revealing-net-neutrality-violations/,"Wehe uses your device to exchange Internet traffic recorded from real, popular apps like YouTube and Spotify—effectively making it look as if you are using those apps. As a result, if an Internet service provider (ISP) tries to slow down an YouTube, Wehe would see the same behavior. We then send the same app’s Internet traffic, but replacing the content with randomized bytes, which prevents the ISPs from classifying the traffic as belonging to the app. Our hypothesis is that the randomized traffic will not cause an ISP to conduct application-specific differentiation (e.g., throttling or blocking), but the original traffic will. We repeat these tests several times to rule out noise from bad network conditions, and tell you at the end whether your ISP is giving different performance to an app’s network traffic.",David Choffnes,Alan Mislove
https://www.khoury.northeastern.edu/research_projects/visualization-of-event-sequences-for-decision-making/,"Many datasets of interest to scientists, analysts, clinicians, and patients include events that take place over time. Events can come from electronic monitoring devices or manual data entry, and all together form an event sequence. By analyzing event sequences, we can make inferences about complex behaviors over time. Interactive visualization tools are an important tool for human decision makers to use for exploring and understanding data. However, the existing visualization techniques need to be improved to support interpretation of data in applications with a large number of events that vary in frequency, accuracy, and timing. This project will create new visualization encoding and interaction design techniques that will advance the state of the art for understanding long streams of event sequences. Techniques will be validated for general uses as well as in a case study on type 1 diabetes treatment decision support. This research will afford more effective data exploration and decision-making tools for analyzing temporal data, applicable to many domains. The resulting visualization techniques will benefit clinicians and patients performing intensive insulin management for type 1 diabetes by enabling them to reduce the burden of care and improve outcomes. In addition, there are immediate applications to the treatment of chronic heart failure as well as non-health domains such as data centers monitoring cyber security. The outreach efforts in this research will disseminate the findings to the type 1 diabetes community, including both caregivers and patients, as well as encourage teenage girls to pursue careers in STEM.",Cody Dunne,Cody Dunne
https://www.khoury.northeastern.edu/research_projects/virtual-coach-for-atrial-fibrillation-support/,"When deployed on smartphones, virtual agents have the potential to deliver life-saving advice regarding emergency medical conditions, as well as provide a convenient channel for health education to improve the safety and efficacy of pharmacotherapy.

We are developing a smartphone-based virtual agent that provides counseling to patients with Atrial Fibrillation. Atrial Fibrillation is a highly prevalent heart rhythm disorder and is known to significantly increase the risk of stroke, heart failure and death. In this project, a virtual agent is deployed in conjunction with a smartphone-based heart rhythm monitor that lets patients obtain real-time diagnostic information on the status of their atrial fibrillation and determine whether immediate action may be needed.",Timothy W. Bickmore,Timothy W. Bickmore
https://www.khoury.northeastern.edu/research_projects/verifying-threaded-software-using-resource-bounds-an-approach-towards-dependable-concurrency/,"Software development is facing a paradigm shift towards ubiquitous concurrent programming, giving rise to software that is among the most complex technical artifacts ever created by humans. Concurrent programming presents several risks and dangers for programmers who are overwhelmed by puzzling and irreproducible concurrent program behavior, and by new types of bugs that elude traditional quality assurance techniques. If this situation is not addressed, we are drifting into an era of widespread unreliable software, with consequences ranging from collapsed programmer productivity, to catastrophic failures in mission-critical systems.

This project will take steps against a concurrent software crisis, by producing verification technology that assists non-specialist programmers in detecting concurrency errors, or demonstrating their absence. The proposed technology will confront the concurrency explosion problem that verification methods often suffer from. The project’s goal is a framework under which the analysis of programs with unbounded concurrency resources (such as threads of execution) can be soundly reduced to an analysis under a small constant resource bound, making the use of state space explorers practical. As a result, the project will largely eliminate the impact of unspecified computational resources as the major cause of complexity in analyzing concurrent programs. By developing tools for detecting otherwise undetectable misbehavior and vulnerabilities in concurrent programs, the project will contribute its part to averting a looming software quality crisis.",Thomas Wahl,Thomas Wahl
https://www.khoury.northeastern.edu/research_projects/career-verified-compilers-for-a-multi-language-world/,"Compilers play a critical role in the production of software and should be correct by preserving the behavior of all programs they compile. Verified compilers guarantee correct compilation of components and support linking with arbitrary target code, no matter its source. To achieve this, a formal semantics of interoperability between source and target languages is required. Additionally, a gradually type-safe target language based on LLVM is needed to support safe interoperability between components compiled from different languages. This project aims to develop a proof architecture for building verified compilers for today's world of multi-language software, benefiting software systems by enabling verified compilation of components.",Amal Ahmed,Amal Ahmed
https://www.khoury.northeastern.edu/research_projects/using-big-data-to-quantify-and-cultivate-genius/,"Far from being solo achievers acknowledged for pure achievement, geniuses may be largely the products of their networks. The goal of this research is to use big data to quantify and cultivate genius. The researchers will analyze data from newly searchable records containing the career paths, associations, and publication records of nearly every scientist working from the early 1900s until today. In the realm of fine art, a quite different but comparable dataset has been assembled to track things like gallery shows, institutional affiliations, and auction prices. The researchers will also scour books, articles, and archives to come up with a detailed sampling of people whom societies have deemed geniuses across many fields and eras. Once complete, the set of geniuses can be analyzed along with the control data both to see what geniuses have in common and how they differ from contemporaries in their fields, with the goal of understanding both what it takes for a high-achiever to “become” a genius — and what a society can do to encourage the development of the potential geniuses in its midst.",Albert-Laszlo Barabasi,Roberta Sinatra
https://www.khoury.northeastern.edu/research_projects/chs-medium-collaborative-research-understanding-online-creative-collaboration-over-multidimensional-networks/,"This research investigates the structure and dynamics of online collaboration. It aims to understand how multidimensional network configurations impact the success of value-creation processes within crowdsourcing systems and online communities. The project employs computational social science approaches to theorize and research the roles of social structure and influence within technology-mediated communication and cooperation processes. The findings will inform decisions on optimizing collaboration in various fields and guide system designers in developing features for effective collaboration. Additionally, managers will gain insights into using crowdsourcing solutions for innovation and marketing strategies, including peer-to-peer marketing. By analyzing digital trace data, the research explores population-level human interaction within crowdsourcing systems. It examines multidimensional networks, including affiliation, communication, affinity, and purchasing relationships, to understand how these structures enable large-scale collaboration. The project analyzes both online community activity and offline purchasing behavior to determine the economic consequences of online interactions. It contributes to the literature by examining network structures, modeling the feedback of success into value-creation processes, and developing methods to predict the economic success of creative products generated online. The research employs various computational and statistical approaches and shares technical resources and theoretical insights with the broader scientific community.",Christoph Riedl,Christoph Riedl
https://www.khoury.northeastern.edu/research_projects/trellis-privilege-separation-for-multi-user-applications-made-easy/,"Operating systems provide a wide variety of resource isolation and access control mechanisms, ranging from traditional user-based security models to fine-grained permission systems as found in modern mobile operating systems. However, comparatively little assistance is available for defining and enforcing access control policies within multiuser applications. These applications, often found in enterprise environments, allow multiple users to operate at different privilege levels in terms of exercising application functionality and accessing data. Developers of such applications bear a heavy burden in ensuring that security policies over code and data in this setting are properly expressed and enforced. We present Trellis, an approach for expressing hierarchical access control policies in applications and enforcing these policies during execution. The approach enhances the development toolchain to allow programmers to partially annotate code and data with simple privilege level tags, and uses a static analysis to infer suitable tags for the entire application. At runtime, policies are extracted from the resulting binaries and are enforced by a modified operating system kernel. Our evaluation demonstrates that this approach effectively supports the development of secure multi-user applications with modest runtime performance overhead.",Engin Kirda,William Robertson
https://www.khoury.northeastern.edu/research_projects/chs-medium-transforming-scientific-presentations-with-co-presenter-agents/,"Although oral scientific presentations are vital for disseminating research findings and inspiring audiences, they have not significantly evolved since the introduction of software like PowerPoint. This project aims to revolutionize these presentations using an intelligent, autonomous co-presenter agent that collaborates with the human presenter in preparing and delivering the talk. The agent will monitor the presenter's speech and gestures, audience feedback, and presentation media, dynamically choreographing these elements to maximize audience engagement and communication. The project will contribute to human-agent collaboration, artificial intelligence, computational linguistics, and human-computer interaction, advancing methods for human presenters to interact with co-presenter agents and presentation media. By amplifying presenters' abilities, the project will enhance the effectiveness of scientific presentations, potentially inspiring future generations to pursue careers in STEM fields.",Timothy W. Bickmore,Timothy W. Bickmore
https://www.khoury.northeastern.edu/research_projects/nets-medium-towards-transparency-of-personalization-on-the-web/,"This project will develop new research methods to map and quantify the ways in which online search engines, social networks, and e-commerce sites use sophisticated algorithms to tailor content to each individual user. This “personalization” may often be of value to the user, but it also has the potential to distort search results and manipulate the perceptions and behavior of the user. Given the popularity of personalization across a variety of Web-based services, this research has the potential for extremely broad impact. Being able to quantify the extent to which Web-based services are personalized will lead to greater transparency for users, and the development of tools to identify personalized content will allow users to access information that may be hard to access today.",Christo Wilson,Alan Mislove
https://www.khoury.northeastern.edu/research_projects/career-towards-methodologies-and-tools-for-conducting-algorithm-audits/,"This project will develop methodologies and tools for conducting algorithm audits. An algorithm audit uses controlled experiments to examine an algorithmic system, such as an online service or big data information archive, and ascertain (1) how it functions, and (2) whether it may cause harm. Examples of documented harms by algorithms include discrimination, racism, and unfair trade practices. Although there is rising awareness of the potential for algorithmic systems to cause harm, actually detecting this harm in practice remains a key challenge. Given that most algorithms of concern are proprietary and non-transparent, there is a clear need for methods to conduct black-box analyses of these systems. Numerous regulators and governments have expressed concerns about algorithms, as well as a desire to increase transparency and accountability in this area.

This research will develop methodologies to audit algorithms in three domains that impact many people: online markets, hiring websites, and financial services. Auditing algorithms in these three domains will require solving fundamental methodological challenges, such as how to analyze systems with large, unknown feature sets, and how to estimate feature values without ground-truth data. To address these broad challenges, the research will draw on insights from prior experience auditing personalization algorithms. Additionally, each domain also brings unique challenges that will be addressed individually. For example, novel auditing tools will be constructed that leverage extensive online and offline histories. These new tools will allow examination of systems that were previously inaccessible to researchers, including financial services companies. Methodologies, open-source code, and datasets will be made available to other academic researchers and regulators.

This project includes two integrated educational objectives: (1) to create a new computer science course on big data ethics, teaching how to identify and mitigate harmful side-effects of big data technologies, and (2) production of web-based versions of the auditing tools that are designed to be accessible and informative to the general public, that will increase transparency around specific, prominent algorithmic systems, as well as promote general education about the proliferation and impact of algorithmic systems.",Christo Wilson,Christo Wilson
https://www.khoury.northeastern.edu/research_projects/csr-small-towards-confederated-web-based-services/,"Users today have access to a broad range of free, web-based social services. All of these services operate under a similar model: Users entrust the service provider with their personal information and content, and in return, the service provider makes their service available for free by monetizing the user-provided information and selling the results to third parties (e.g., advertisers). In essence, users pay for these services by providing their data (i.e., giving up their privacy) to the provider.

This project is using cloud computing to re-architect web-based services in order to enable end users to regain privacy and control over their data. In this approach—a confederated architecture—each user provides the computing resources necessary to support her use of the service via cloud providers. All user data is encrypted and not exposed to any third-parties, users retain control over their information, and users access the service via a web browser as normal.

The incredible popularity of today’s web-based services has lead to significant concerns over privacy and user control over data. Addressing these concerns requires a re-thinking of the current popular web-based business models, and, unfortunately, existing providers are dis-incentivized from doing so. The impact of this project will potentially be felt by the millions of users who use today’s popular services, who will be provided with an alternative to the business models of today.",Alan Mislove,Christo Wilson
https://www.khoury.northeastern.edu/research_projects/towards-an-evolvable-public-key-infrastructure/,"The Public Key Infrastructure (PKI) is a crucial component of the Internet, providing secure and authenticated communication. However, the PKI has faced challenges in evolving to meet new security concerns and Internet demands. This project introduces assertion-carrying certificates (ACCs), a new technology that enables certificates to include code for evaluation during the validation process. ACCs are applied to facilitate certificate authorities' adaptation to changing certificate delegation and automated issuance demands. Additionally, ACCs and trusted execution environments are utilized to enable web-hosting services to securely manage their customers' cryptographic keys. By developing a new, extensible approach to constraining when identities on the Internet should be trusted, this project aims to make it easier and safer to extend the PKI's capabilities, allowing it to evolve to meet future challenges. The project's code and data will be publicly available for research and deployment.",Taejoong Chung,Christo Wilson
https://www.khoury.northeastern.edu/research_projects/ices-large-collaborative-the-role-of-space-time-and-information-in-controlling-epidemics/,"The control of epidemics relies on interventions that are often voluntary. People's self-interest and behavioral changes impact the effectiveness of these interventions. This project aims to study the foundations of policy design for controlling epidemics using epidemic games on complex networks involving uncertainty, temporal evolution, and learning. It will develop models to capture the complexity of interactions and information exchange and study policies for controlling epidemics. The project integrates approaches from Computer Science, Economics, Mathematics, and Epidemiology and includes curriculum development and a multi-disciplinary workshop for education and outreach.",Rajmohan Rajaraman,Ravi Sundaram
https://www.khoury.northeastern.edu/research_projects/the-other-abilities/,"Sensory Translation in Art explores sensory translation as a means to make art accessible and inclusive. The project investigates the differences between describing an artwork and experiencing it through a different sense using technology. It aims to create alternative ways to experience art by transferring between senses, akin to translating between languages. The project collaborates with artists, composers, engineers, and an art theorist to explore these themes.","Eva Fotiadi
Andreas Tegnander
Mark IJzerman
Alina Ozerova
Ildikó Horvath
Claudio F Baroni
Maria Kandyla
Michele Abolaffio
VibraFusionLabCollective
David Bobier
Jim Ruxton
Jenelle Rouse
Christine ‘Coco’ Roschaert
Rebecca Kleinberger
Akito van Troyer
Mor Efrati
Yonatan Cohen",Eva Fotiadi
https://www.khoury.northeastern.edu/research_projects/the-open-islamicate-texts-initiative-arabic-script-ocr-catalyst-project-openiti-aocp/,"The textual production of the diverse premodern Islamicate cultures stretching from modern Spain to South Asia is one of the most prolific in human history, making it an ideal candidate for digitally enhanced methods of search and analysis. Yet, our ability to bring these diverse literary traditions into the digital realm has been repeatedly frustrated by the underperformance of the currently available OCR solutions for Arabic-script languages. On top of this poor performance, several of them are also prohibitively expensive for academic users and offer limited trainability. For this reason, by late 2016 OpenITI’s work increasingly began to focus on the development of improved open-source OCR for Persian and Arabic through a collaboration with Benjamin Kiessling, then a computer scientist at Leipzig University’s (LU) Alexander von Humboldt Chair for Digital Humanities (now at Université Paris Sciences et Lettres). This collaboration led to a series of studies on Kiessling’s new OCR engine, Kraken, which demonstrated that its neural network-based approach to OCR (now implemented in Tesseract 4’s most recent release too) could routinely achieve accuracy rates on Persian and Arabic print books greater than 97% and, at times, even greater than 98%.",David Smith,Matthew Thomas Miller
https://www.khoury.northeastern.edu/research_projects/the-integrative-genomics-of-acute-asthma-control/,"This project aims to identify the molecular basis of poor asthma control in a well-characterized cohort of asthmatic patients with available genetic, gene expression, and DNA methylation data. Using novel statistical network-modeling approaches, we will model the molecular basis of poor asthma control and define an asthma-control gene network, as well as the genetic, epigenetic, and environmental factors that determine inter-individual differences in asthma control.",Benjamin Raby,Albert-László Barabási
https://www.khoury.northeastern.edu/research_projects/the-control-principles-of-complex-systems/,"Many complex systems, such as human cells, societies, and economic systems, lack obvious control mechanisms. This project proposes that the architecture of these systems is driven by the need for sufficient control to maintain functionality. Uncovering the control principles of complex self-organized systems could reveal fundamental laws governing them.",Albert-László Barabási,Jean-Jacques Slotine
https://www.khoury.northeastern.edu/research_projects/tamago-phone/,"TamagoPhone is a framework and approach that supplements existing egg incubation techniques with a two-way, real-time audio system. It allows parent birds and unhatched eggs to communicate with each other remotely in real-time during incubation. This addresses the issue of depriving embryonic chicks of integral parent-offspring vocal communications during early development, which is common in standard artificial incubation techniques. TamagoPhone includes replacing the real egg with an augmented ""dummy"" egg with a microphone and speaker, which is then cared for by the parent. The artificial incubator is also augmented with microphones and speakers, and both sides are connected by a two-way audio streaming platform. The audio components are inconspicuously integrated, making it possible for parent birds and unhatched eggs to communicate in a natural way while still maintaining the controlled environment of the incubator.",Rebecca Kleinberger,Janelle Sands
https://www.khoury.northeastern.edu/research_projects/medium-table-as-query-unifying-data-discovery-and-alignment/,"Fueled by advances in information extraction and societal trends that value institutional openness and transparency, structured data are being produced and shared at an overwhelming speed. Open data sharing is central to supporting institutional transparency, but transparency is not achieved if shared data cannot be found and effectively aligned with other data being studied by data scientists, journalists, and others. This project will fundamentally contribute to the new science of open data sharing. The requirements for data discovery and integration over heterogeneous table repositories containing structured data are fundamentally different than they are for federated data integration (where for example, all data within an enterprise is integrated) or data exchange (where data is exchanged among a small set of autonomous peers, for example, between two institutions). This project will lay the theoretical foundations of data discovery (identification, alignment, and integration of tables) within table repositories. It will contribute both to developing the right conceptual framework for studying this problem and to designing systems that solve the table discovery and alignment problems at scale.
Today, solutions for data discovery over massive table repositories are in their infancy. Some solutions are highly tied to a specific domain. For example, solutions for finding relevant tables in mass collaboration data (often called web tables) may assume tables are designed for human consumption with rich, human-readable attribute names or metadata, and are relatively small (being designed for display on web pages). Furthermore, solutions often assume that the data scientists know a lot about what data is available and exactly how they want to integrate it with known data. These solutions let a user find tables that join with a specified attribute or union with a query table. But they are inadequate if the best way to extend a query table is to actually join it on several attributes with two other tables and then union the extended result with an existing wider table. This project will develop a more holistic approach to table discovery that both discovers a set of alignable tables as well as the best way to integrate (or align) the new data with a query table. In this new paradigm called “table-as-query”, the user does not need to know a priori on which attributes various tables in a repository are best aligned. This project promotes a research agenda under which discovery finds not a single table, but a set of tables that can be combined (aligned) with the query table. The solutions will include integration choices within the table discovery process, looking for a set of tables that can best be aligned with a query table and also finding what the best alignment is. Importantly, the project will not rely on the unique name assumption, which states that different values refer to different and unique entities. Real data contains synonyms (two values that refer to the same entity) and homographs (one value that refers to more than one entity). This project will define new foundations and mathematical principles for studying table alignment and discovery. The search space is massive, so the project will also develop approximate, scalable solutions that can quickly (at interactive speeds) find a good set of tables and good alignments over massive table repositories with millions of tables.",Renée Miller,Mirek Riedewald
https://www.khoury.northeastern.edu/research_projects/systems-biology-of-airway-disease-core-a/,"The goal of this project is to explore the molecular and network-based similarities and differences between asthma and COPD. Researchers will use network analysis to identify the disease modules for asthma and COPD, and the molecular relationships between them. This work will initially rely on data already collected by investigators, leading to a first round of mechanistic predictions. These predictions will drive the design of subsequent experimental work and data collection, iteratively improving the predictive power of the project. The project has two specific aims: (1) Construct the network infrastructure to predict the disease module relying on data collected by the PPG Projects and Cores; (2) Iteratively enhance the predictive value of the disease module by overlaying data collected by the PPG Projects and Cores. The project will apply network analysis support at different levels: (1) selection and prioritization of the variants and genes associated with airflow obstruction from Project 1; (2) integrating different levels of genomics and transcriptomics data associated with asthma and COPD with the molecular interaction networks (interactome) from Project 2; and (3) identifying and interpreting epigenetic changes (methylation and miRNA) associated with asthma and COPD from Project 3 by integration with protein interactome models",Albert-László Barabási,Albert-László Barabási
https://www.khoury.northeastern.edu/research_projects/summer-school-big-data-and-statistics-for-bench-scientists/,"Northeastern University hosted a Summer School, entitled Big Data and Statistics for Bench Scientists, in the summers of 2016, 2017, and 2018. The attendees were graduate and post-graduate life scientists, working primarily in wet labs generating large datasets. Unlike other educational efforts that emphasize genomic applications, this School targeted scientists working with other experimental technologies. Mass spectrometry-based proteomics and metabolomics was the main focus, however, the School was also appropriate for scientists working with other assays, e.g., nuclear magnetic resonance spectroscopy (NMR), protein arrays, etc. This large community has been traditionally under-served by educational efforts in computation and statistics. This School aimed to fill this void. The Summer School was motivated by feedback from smaller short courses previously co-organized or co-instructed by the PI and covered theoretical and practical aspects of design and analysis of large-scale experimental datasets. The Summer School had a modular format, with 8 20-hour modules scheduled in 2 parallel tracks during 2 consecutive weeks. Each module could be taken independently. The modules were (1) Processing raw mass spectrometric data from proteomic experiments using Skyline, (2) Beginner’s R, (3) Processing raw mass spectrometric data from metabolomic experiments using OpenMS, (4) Intermediate R, (5) Beginner’s guide to statistical experimental design and group comparison, (6) Specialized statistical methods for detecting differentially abundant proteins and metabolites, (7) Statistical methods for discovery of biomarkers of disease, and (8) Introduction to systems biology and data integration. Each module introduced the necessary statistical and computational methodology and contained extensive practical hands-on sessions. Each module was organized by instructors with extensive interdisciplinary teaching experience and supported by several teaching assistants. All the course materials, including videos of the lectures and practical sessions, are publicly available free of charge.",Olga Vitek,Olga Vitek
https://www.khoury.northeastern.edu/research_projects/struct-enabling-secure-and-trustworthy-compartments-in-mobile-applications/,"Society’s dependence on mobile technologies rapidly increases as we entrust mobile applications with more and more private information and capabilities. Existing security research follows a common threat model that treats apps as monolithic entities and only captures attack surface between apps. However, recent research reveals that app internal attacks are emerging quickly as complex entities with conflicting interests are commonly included inside a single app to allow for rich features and fast development.

This project, known as STRUCT, systematically investigates app compartmentalization as a novel and general approach to mitigating the critical yet unaddressed internal threats of apps. It applies this approach to major mobile platforms via solving four challenging and interesting research problems: (1) Deriving principles and models for designing intra-app security mechanisms; (2) Building compiler toolchains for automatically and securely compartmentalizing apps; (3) Building system-level enforcement mechanisms for open platforms; (4) Building app-level system-agnostic enforcement mechanisms for closed platforms. Solutions to these challenges together form a foundation to the design and implementation of intra-app security isolation and policy enforcement, which is currently nonexistent but in high demand.

STRUCT has its broader impact in fostering a new direction in mobile security research and education as well as increasing society’s adoption of mobile technology in security-sensitive scenarios.",Long Lu,Long Lu
https://www.khoury.northeastern.edu/research_projects/twc-medium-collaborative-research-strengthening-wi-fi-network-wide/,"Wi-Fi has become ubiquitous for Internet access, leading to increased complexity and sensitivity of Wi-Fi radios. This project aims to investigate the resiliency of Wi-Fi networks to smart attacks and design robust solutions to resist or counter them. The project will blend theory, experimentation, and prototyping to develop mitigation techniques, algorithms, and open-source software for wireless network cards and access points. The anticipated benefits include a deep understanding of threats facing Wi-Fi, strengthened Wi-Fi networks and emerging standards, and security training for the next generation of radio design and deployment professionals.",Guevara Noubir,Guevara Noubir
https://www.khoury.northeastern.edu/research_projects/shf-small-stabilizing-numeric-programs-against-platform-uncertainties/,"Most computer programs process vast amounts of numerical data. Unfortunately, due to space and performance demands, computer arithmetic comes with its own rules. Making matters worse, different computers have different rules: while there are standardization efforts, efficiency considerations give hardware and compiler designers much freedom to bend the rules to their taste. As a result, the outcome of a computer calculation depends not only on the input, but also on the particular machine and environment in which the calculation takes place. This makes programs brittle and un-portable, and causes them to produce untrusted results. This project addresses these problems, by designing methods to detect inputs to computer programs that exhibit too much platform dependence, and to repair such programs, by making their behavior more robust.",Thomas Wahl,Thomas Wahl
https://www.khoury.northeastern.edu/research_projects/speculator-a-tool-to-analyze-speculative-execution-attacks-and-mitigations/,"Speculator is a tool for studying speculative execution through performance counters. It allows to easily create proof-of-concepts implementations of speculative execution attacks and tests to verify their mitigations. Furthermore, speculator allows very precise measures (u-ops level) of events which gives the ability to reverse engineer speculative execution behavior. Using performance counters makers, it is possible to deterministically observe speculative execution without rely on very noisy and convoluted side-channels.",Engin Kirda,Andrea Mambretti
https://www.khoury.northeastern.edu/research_projects/sonic-and-vocal-enrichment-in-zoos/,"There is a strong disconnect between humans and other species in our societies. Zoos particularly expose this disconnect by displaying the asymmetry between visitors in search of entertainment, and animals often suffering from lack of meaningful interactions and natural behaviors. Enrichment is a way to enhance the quality of life of captive animals, enabling them to express natural behaviors and reducing abnormal stereotypies. Despite the potential for sound-based enrichment and interactivity, current zoo conservation practices are lacking tools and frameworks to leverage innovative technology to improve animal well-being and zookeepers’ ability to care for them. Ethical considerations are called for in the development of such interventions as human understanding of animal’s worlds is still limited, and assumptions can have detrimental consequences. Based on several interventions, we propose four principles to guide a more systematic implementation of sonic enrichment in zoos. Our goal is to lay the groundwork for the design of the zoos of the future, with a focus on sounds, for the benefit of the animals.",Rebecca Kleinberger,Rebecca Kleinberger
https://www.khoury.northeastern.edu/research_projects/smart-and-connected-churches-for-promoting-health-in-disadvantaged-populations/,"This project focuses on development of technologies to improve population health for an underserved urban community in Boston. We are working with communities in a network of 12 churches in the Boston area, along with volunteers who provide health promotion outreach (“Health Ministry”), the church leadership, and a community liaison affiliated with a hospital, to improve the overall health of this predominately African American community. African Americans struggle significantly more with many health behaviors (e.g., smoking, physical activity) and have significantly higher rates of many chronic health conditions (e.g., diabetes, hypertension), compared to other racial and ethnic groups. In this effort, we are collaborating with members of the Black Ministerial Alliance of Boston and Health Ministry leaders of member churches to develop a range of sensing, monitoring, and messaging technologies to provide a smartphone-based conversational agent system that can improve health for community members. The system will empower this community of individuals to collectively solve health-relevant problems it identifies as important, such as exercise and diet promotion.",Timothy W. Bickmore,Timothy W. Bickmore
https://www.khoury.northeastern.edu/research_projects/signaligner-pro/,"Human activity recognition using wearable accelerometers can enable in-situ detection of physical activities to support novel human-computer interfaces. Activity recognition algorithms use data on the motion and orientation of limbs to detect activities such as walking, sitting, and sleeping, among others. Many of the machine-learning-based algorithms require multi-person, multi-day, carefully-annotated training data with precisely marked start and end times of the activities of interest. To date, there is a dearth of usable tools that enable researchers to conveniently visualize and annotate multiple days of high-sampling-rate raw accelerometer data. We developed “Signaligner Pro” – a data annotation tool to enable researchers to conveniently and quickly explore and annotate multi-day high-sampling rate raw sensor data with the assistance from state-of-the-art activity recognition algorithms. The tool visualizes high-sampling rate raw data and time-stamped annotations generated by existing activity recognition algorithms; the annotations can then be directly modified by the researchers to create their own, improved, labeled datasets.",,
https://www.khoury.northeastern.edu/research_projects/shf-small-secure-compilation-of-advanced-languages/,"Advanced programming languages, based on dependent types, enable program verification alongside program development, thus making them an ideal tool for building fully verified, high assurance software. Recent dependently typed languages that permit reasoning about state and effects—such as Hoare Type Theory (HTT) and Microsoft’s F*—are particularly promising and have been used to verify a range of rich security policies, from state-dependent information flow and access control to conditional declassification and information erasure. But while these languages provide the means to verify security and correctness of high-level source programs, what is ultimately needed is a guarantee that the same properties hold of compiled low-level target code. Unfortunately, even when compilers for such advanced languages exist, they come with no formal guarantee of correct compilation, let alone any guarantee of secure compilation—i.e., that compiled components will remain as secure as their high-level counterparts when executed within arbitrary low-level contexts. This project seeks to demonstrate how to build realistic yet secure compilers. This is a notoriously difficult problem. On one hand, a secure compiler must ensure that low-level contexts cannot launch any “attacks” on the compiled component that would have been impossible to launch in the high-level language. On the other hand, a realistic compiler cannot simply limit the expressiveness of the low-level target language to achieve the security goal.",Amal Ahmed,Amal Ahmed
https://www.khoury.northeastern.edu/research_projects/career-scaling-approximate-inference-and-approximation-aware-learning-national-science-foundation/,The project aims to scale approximate inference by generalizing two scalable methods and developing scalable approximation-aware learning methods. The hypothesis is that this approach will increase end-to-end prediction accuracy and scalability. The project focuses on four sub-problems: (1) approximating probabilistic conjunctive queries with relational databases; (2) learning probabilities in uncertain databases based on feedback; (3) approximating exact probabilistic inference in undirected graphical models; and (4) developing a framework for learning linearized potentials from partially labeled data.,Wolfgang Gatterbauer,Dan Suciu
https://www.khoury.northeastern.edu/research_projects/ci-en-collaborative-run-your-research-with-redex/,"This project focuses on developing REDEX, a tool for modeling programming languages for software development. With REDEX, users can create models of programming languages as software artifacts, allowing them to test consistency, explore properties, and check claims. This project aims to improve REDEX by creating a modular system, enhancing scalability for large models, and improving testing and error detection. It also includes support for user education through tutorials and workshops.",Matthias Felleisen,Matthias Felleisen
https://www.khoury.northeastern.edu/research_projects/onr-roseta-5g-robust-and-secure-tactical-5g-slice/,"In this project, we have focused on analyzing security vulnerabilities in the latest 5G systems and developing and analyzing provably secure solutions that protect against sophisticated attacks targeting resiliency, security and privacy.",Guevara Noubir,Guevara Noubir
https://www.khoury.northeastern.edu/research_projects/rocket-scalable-and-agile-analysis-of-mass-spectrometry-experiments/,"Mass spectrometry rapidly generates complex and large datasets that necessitate new statistical methods and tools for analysis. ROCKET builds an enabling technology for working with large mass spectrometric datasets in R and rapidly developing new algorithms. It supports scaling down and scaling up analyses, generates efficient mixtures of R and target code, and ensures compatibility with mass spectrometry-specific open data storage standards. ROCKET democratizes access to R-based data analysis for a broader community of life scientists and creates a blueprint for a new paradigm for R-based computing with large datasets.",Olga Vitek,Jan Vitek
https://www.khoury.northeastern.edu/research_projects/robotreviewer/,"Evidence Based Medicine (EBM) aims to systematically use the best available evidence to inform medical decision making. This paradigm has revolutionized clinical practice over the past 30 years. The most important tool for EBM is the systematic review, which provides a rigorous, comprehensive and transparent synthesis of all current evidence concerning a specific clinical question. These syntheses enable decision makers to consider the entirety of the relevant published evidence.

Systematic reviews now inform everything from national health policy to bedside care. But producing these reviews requires researchers to identify the entirety of the relevant literature and then extract from this the information to be synthesized; a hugely laborious and expensive exercise. Moreover, the unprecedented growth of the biomedical literature has increased the burden on those trying to make sense of the published evidence base. Concurrently, more systematic reviews are being conducted every year to synthesize the expanding evidence base; tens of millions of dollars are spent annually conducting these reviews.

RobotReviewer aims to mitigate this issue by (semi-) automating evidence synthesis using machine learning and natural language processing.",Byron Wallace,
https://www.khoury.northeastern.edu/research_projects/career-rethinking-mobile-security-in-the-new-age-of-app-as-a-platform/,"An ongoing evolution in the design of mobile applications (apps) and services, called “app-as-a-platform”, is posing fundamental challenges to mobile security and privacy, exposing consumers, enterprises, and governments to new threats. Existing security technologies were not designed to address apps’ emerging role as micro-platforms and are, therefore, incapable of providing sufficient protections. This research project is developing security foundations in three dimensions of app-as-a-platform architectures: (1) In-app Dimension, where modules within the same app can adversely affect or manipulate one another, (2) App-cloud Dimension, where apps may spy on or abuse integrated cloud services, and vice versa, and (3) App-IoT Dimension, where unauthorized apps can manipulate IoT (Internet-of-Things)-connected devices.",Long Lu,Long Lu
https://www.khoury.northeastern.edu/research_projects/responsible-computer-science-challenge/,"Today, computer scientists wield tremendous power, but when that power isn't coupled with responsibility, the results can have unintended consequences, negatively impacting users’ privacy, security, or wellbeing. The Responsible Computer Science Challenge aims to educate a new wave of engineers who bring holistic thinking to the design of technology products by supporting the integration of ethics with undergraduate computer science training. The Challenge awarded $3.5 million in prizes to promising approaches to embedding ethics into undergraduate computer science education, empowering graduating engineers to drive a culture shift in the tech industry and build a healthier internet.",The provided text does not specify the name of the professor leading the research.,Omidyar
https://www.khoury.northeastern.edu/research_projects/af-small-research-in-complexity-theory/,"Computational inefficiency is a common experience: the computer cannot complete a certain task due to lack of resources such as time, memory, or bandwidth. The theory of computational complexity classifies — or aims to classify — computational tasks according to their inherent inefficiency. Inefficiency can also be harnessed to our advantage. Indeed, modern cryptography and electronic commerce rely on the (presumed) inefficiency of certain computational tasks. From the study of computational complexity there have arisen questions that stand as grand challenges of contemporary science. The objective of this project is to enrich the theory of computational complexity with new directions and techniques, and to use these techniques to make progress on long-standing open problems. Specific areas of investigation include the complexity of sampling tasks and of distributed tasks, and randomness. The investigator has a track record of fruitful exchanges with the mathematics community and will foster further cross-fertilization between mathematics and computer science. The project will develop publicly-available educational material, including lecture notes, surveys, slides, and videos, both at the advanced and at the introductory level.",Emanuele Viola,Emanuele Viola
https://www.khoury.northeastern.edu/research_projects/tools-to-help-digital-workers-earn-more-and-create-fairer-workspaces/,"Gig markets rely on reviews to help customers or employers identify the workers they want to hire. However, gig markets have been plagued with unfair assessments containing inaccurate reputation signals about workers which can not only limit workers’ future job opportunities, but can also result in workers not getting paid or even being terminated from the marketplace. Unfair reviews are generally created because employers have a hard time differentiating the factors within the workers’ control and the ones that have little to do with their performance (e.g., when they complain about an Uber driver getting stuck in traffic). However, because market power is typically placed in the hands of employers, a bad worker review can result in the worker losing her entire livelihood.
To address this problem, we present Reputation Agent, a review validation system that helps employers to generate fair reviews. Reputation Agent implements an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors that are outside the control of the gig worker, according to the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. Reputation Agent, in contrast with traditional approaches, motivates customers and employers to review gig workers’ performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy, spark discussions around the established gig market rules, and could be used to help platform maintainers identify potential injustices towards workers generated by their interfaces. Our vision is that with truth and transparency we can bring fairer treatment of gig workers.",Saiph Savage,Angela Richmond
https://www.khoury.northeastern.edu/research_projects/recon-revealing-and-controlling-privacy-leaks-in-mobile-network-traffic/,"This project focuses on the auditing and control of personally identifiable information leaks, addressing the key challenges of how to identify and control personal identifying information (PII) leaks when users’ PII is not known a priori, nor is the set of apps or devices that leak this information. To enable auditing through improved transparency, we are investigating how to use machine learning to reliably identify PII from network flows, and identify algorithms that incorporate user feedback to adapt to the changing landscape of privacy leaks. We are also investigating the extent to which our approach extends to privacy leaks from IoT devices. Besides adapting our system to the unique format for leaks across a variety of IoT devices, our work investigates PII exposed indirectly through time-series data produced by IoT-generated monitoring. Using results from those investigations, we are building tools that allow users to control how their information is (or not) shared with other parties. Our tool ReCon analyzes your network traffic to tell if personal information is being transmitted, without needing to know a user’s personal information to work. It detects device/user identifiers used in tracking, geolocation leaks, unsafe password transmissions, and personal information such as name, address, gender, and relationship status. This information is made available to the user via a private Web page, and allows them to tell us if we found important leaks, and whether we should block or modify the leaks.",David Choffnes,Arnaud Legout
https://www.khoury.northeastern.edu/research_projects/rearm-protecting-arm-binaries-via-load-time-reduction-and-run-time-read-protection/,,Long Lu,Long Lu
https://www.khoury.northeastern.edu/research_projects/cps-quantitative-visual-sensing-of-dynamic-behaviors-for-home-based-progressive-rehabilitation/,"The aim of this project is to develop a comprehensive cyber-physical framework by combining computer vision and robotics to enable intelligent human-environment interaction. We focus on individualized remote rehabilitation using an intelligent, adjustable lower limb orthotic brace to manage knee osteoarthritis. We use computer vision to track and record patient-device interactions, abstract them into parametric and composable manifold representations, and link them to quantitative biomechanical assessments of the patients. This helps us develop personalized user models and exercise regimens, and progressively refine exercises and brace adjustments. Our approach enables us to understand human neuro-musculo-skeletal and locomotion principles by integrating quantitative data acquisition, lower-order modeling, and individualized feedback. This will lead to fundamental insights into the generative hypotheses of human actions, as our quantitative visual models capture underlying physical, physiological, and behavioral mechanisms based on biomechanical assessments. This research has the potential to improve mobility and reduce pain in patients with knee osteoarthritis, and the home-based rehabilitation setting offers flexibility and accessibility to a larger patient population.",Yun Raymond Fu,Yun Raymond Fu
https://www.khoury.northeastern.edu/research_projects/nsf-satc-frontier-properdata/,"This project seeks to protect personal information by improving the transparency and control of data flow on the Internet, using a multidisciplinary approach that combines methodologies from computer science (theory, network measurement, security) with policy and economics, and crosses multiple application domains (web, mobile, and Internet-of-Things). Conceptual frameworks are developed for personal information flow on the Internet, as well as systems for monitoring and mediation. Existing systems are improved for measuring the tracking and discrimination of personal information, and for explicitly controlling privacy-utility tradeoffs. To provide long-term privacy-by-design alternatives, the project pursues verifiable IoT architectures seeking to decentralize the advertising ecosystem and eliminate intermediaries. The project likewise leverages technology to inform policy specification and to provide tools to audit and enforce policies. The broader impacts of the project include: (1) informing policymakers, nonprofit advocates, and industry players through interactions with relevant stakeholders; (2) training next-generation graduate and undergraduate students jointly in technology and policy; and (3) broadening participation of women, underrepresented minorities, and community college students.",David Choffnes,Alan Mislove
https://www.khoury.northeastern.edu/research_projects/csr-small-privacy-and-security-for-mapreduce-clouds-with-pasmac/,"Despite the hype, only a few large enterprises or governmental organizations outsource their services to public clouds. On the one hand, cloud computing has been identified as one of the top ten business strategies as it offers many advantages such as greater flexibility and reduced costs. However, on the other hand, outsourcing and, therewith, relinquishing control of services implies many security and privacy problems. Cloud providers often place their data centers in foreign countries where security policies are difficult to enforce, cloud infrastructures are threatened by hackers, insiders, and even malicious customers trying to peek into or tamper with outsourced data. Consequently, the cloud cannot be trusted. As of today, lack of security and privacy guarantees are major adoption obstacles for both, large enterprises and governmental organizations.
PASMAC targets the design and evaluation of protocols for secure and privacy- preserving “data analysis” in an untrusted cloud. With PASMAC, the user can store and query data in the cloud, preserving privacy and integrity of outsourced data and queries. PASMAC specifically addresses a real-world cloud framework: Google’s prominent MapReduce paradigm. PASMAC will design and prototype new protocols based on highly parallelizable, efficient privacy-preserving techniques, such as efficient private information retrieval, encrypted Bloom filters, and additive homomorphic encryption.",Guevara Noubir,Erik-Oliver Blass
https://www.khoury.northeastern.edu/research_projects/principled-compiling-and-linking-for-multi-language-software/,"When building large software systems, programmers should be able to use the best language for each part of the system. But when a component written in one language becomes part of a multi-language system, it may interoperate with components that have features that don’t exist in the original language. This affects programmers when they refactor code (i.e., make changes that should result in equivalent behavior). Since programs interact after compilation to a common target, programmers have to understand details of linking and target-level interaction when reasoning about correctly refactoring source components. Unfortunately, there are no software toolchains available today that support single-language reasoning when components are used in a multi-language system. This project will develop principled software toolchains for building multi-language software. The project’s novelties include (1) designing language extensions that allow programmers to specify how they wish to interoperate (or link) with conceptual features absent from their language through a mechanism called linking types, and (2) developing compilers that formally guarantee that any reasoning the programmer does at source level is justified after compilation to the target. The project has the potential for tremendous impact on the software development landscape as it will allow programmers to use a language close to their problem domain and provide them with software toolchains that make it easy to compose components written in different languages into a multi-language software system.
The project will evaluate the idea of linking types by extending ML with linking types for interaction with Rust, a language with first-class control, and a normalizing language, and developing type preserving compilers to a common typed LLVM-like target language. The project will design a rich dependently typed LLVM-like target language that can encapsulate effects from different source languages to support fully abstract compilation from these languages. The project will also investigate reporting of cross-language type errors to aid programmers when composing components written in different languages.",Amal Ahmed,Amal Ahmed
https://www.khoury.northeastern.edu/research_projects/personal-virtual-networks/,"The Personal Virtual Network describes a new networking abstraction which provides each device with its own virtual network that a user can configure and control. PVN will allow devices to establish trusted network configurations inside the providers, define policies for their network traffic and even deploy software that interposes on the traffic.",David Choffnes,David Choffnes
https://www.khoury.northeastern.edu/research_projects/personal-networks-of-football-players-association-with-functional-cardiac-and-cognitive-outcomes/,"Retired NFL football players experience changes to their social life due to transitions away from a team environment, change of leisure activities, and need to re-define relationships with family and friends. The resulting personal networks affect physical health and the aging process. This targeted study aims to characterize the personal networks of former football players using a web-based survey, and look for links with cognitive, cardiac, and functional outcomes.",Albert-László Barabási,Albert-László Barabási
https://www.khoury.northeastern.edu/research_projects/orca-talk/,"We design and implement a system for acoustically interacting with cetaceans in the wild in which acoustic signals flow in both directions simultaneously (full-duplex), featuring digital echo-suppression. We tested the system in a pilot experiment in Arctic Norway, where killer whales and humpback whales cruise the waters. The full-duplex system allowed us to vocally interact with the underwater acoustic scene by being able to listen while producing sounds.",Rebecca Kleinberger,Jorg Rychen
https://www.khoury.northeastern.edu/research_projects/iii-small-optimal-allocation-of-crowdsourced-resources-for-information-retrieval-evaluation/,"Evaluating the performance of information retrieval systems, such as search engines, is critical to their effective development. Current “gold standard” performance evaluation methodologies generally rely on the use of expert assessors to judge the quality of documents or web pages retrieved by search engines, at great cost in time and expense. The advent of “crowd sourcing,” such as available through Amazon’s Mechanical Turk service, holds out the promise that these performance evaluations can be performed more rapidly and at far less cost through the use of many (though generally less skilled) “crowd workers”; however, the quality of the resulting performance evaluations generally suffer greatly. The thesis of this project is that one can obtain the best of both worlds — performance evaluations with the quality of experts but at the cost of crowd workers — by optimally leveraging both experts and crowd workers in asking the “right” assessor the “right” question at the “right” time. For example, one might ask inexpensive crowd workers what are likely to be “easy” questions while reserving what are likely to be “hard” questions for the expensive experts. While the project focuses on the performance evaluation of search engines as its use case, the techniques developed will be more broadly applicable to many domains where one wishes to efficiently and effectively harness experts and crowd workers with disparate levels of cost and expertise.",Javed Aslam,Javed Aslam
https://www.khoury.northeastern.edu/research_projects/observatory-for-online-human-and-platform-behavior/,"The Observatory for Online Human and Platform Behavior aims to construct a research infrastructure that securely and ethically collects data on the online behavior of a large sample of volunteers and the algorithmically driven decisions of major Internet platforms. This data will enable a wide range of research on the Internet, including the state of the information ecosystem, damaging online behavior, and various aspects of the online world. The infrastructure will provide high-quality data on human and platform behavior at a scale and granularity that will allow transformational investigation of the online world.",David Lazer,David Lazer
https://www.khoury.northeastern.edu/research_projects/af-small-network-algorithms-under-adversarial-and-stochastic-uncertainty/,"Modern information networks composed of heterogeneous nodes and links, whose capacities and capabilities change unexpectedly due to mobility, failures, maintenance, and adversarial attacks.  This project studies the design of highly robust networked systems that are resilient to extreme failures and rapid dynamics, and provide optimal performance under a wide spectrum of scenarios with varying levels of predictability.
The focus of this project will be on two problem domains, which together address adversarial network dynamics and stochastic network failures.  The first component is a comprehensive theory of information spreading in dynamic networks.  The PI will develop an algorithmic toolkit for dynamic networks, including local gossip-style protocols, network coding, random walks, and other diffusion processes.  The second component of the project concerns failure-aware network algorithms that provide high availability in the presence of unexpected and correlated failures.  The PI will study failure-aware placement of critical resources, and develop flow and cut algorithms under stochastic failures using techniques from chance-constrained optimization.  Algorithms tolerant to adversarial and stochastic uncertainty will play a critical role in large-scale heterogeneous information networks of the future.",Rajmohan Rajaraman,Rajmohan Rajaraman
https://www.khoury.northeastern.edu/research_projects/national-deep-inference-fabric-ndif/,"The National Deep Inference Fabric (NDIF) project will develop a new kind of scientific computational infrastructure that will allow researchers to design scientific experiments by writing code that inspects and modifies the calculations deep within a network while it’s making predictions or conducting conversations. In other words, it will allow scientists to study how a network performs “inference”: how it processes inputs to yield outputs, and how its detailed internal computations lead to its predictions.",David Bau,David Bau
https://www.khoury.northeastern.edu/research_projects/narrative-based-training-simulations-using-theory-of-mind/,"This research explores developing procedural narrative systems using crowd-sourcing methods. The aim is to create a framework for simulation-based training that supports learner exploration and replay and exercises theory of mind skills to deliver the full promise of social skills training. The research begins with a paradigm shift that re-conceptualizes social skills simulation as a learner rehearsing a role instead of performing a role. This shift will exploit Stanislavsky’s Active Analysis (AA), a performance rehearsal technique that explicitly exercises Theory of Mind skills. Further, AA’s decomposition into short rehearsal scenes can break the combinatorial explosion over long narrative arcs that exacerbates content creation for social training systems. The research will then explore using behavior fitting and machine learning techniques on crowd-sourced data as way to semi-automate the development of multi-agent simulations for social training. The research will assess quantitatively and qualitatively the ability of this approach to (a) provide experiences that support exploration and foster ToM use and (b) support acquiring crowd-sourced data that can be used to craft those experiences using automatic methods.",Stacy C. Marsella,Magy Seif El-Nasr
https://www.khoury.northeastern.edu/research_projects/multi-functional-optical-meta-systems-enabled-by-deep-learning-aided-inverse-design/,"Artificial intelligence, particularly deep learning, has revolutionized academia and industry. This project aims to develop a generative and versatile design approach based on deep learning to create multi-functional photonic systems. Deep learning can unveil complex relationships between photonic structures and their properties, enabling the accelerated design of devices with distinct functionalities in response to wavelength, polarization, and other parameters. These multi-functional systems have applications in optical imaging, holographic displays, biomedical sensing, and consumer photonics. The project also includes outreach activities to educate students in grades 7-12 and provides graduate and undergraduate students with hands-on experience in photonics, deep learning, and advanced manufacturing.",Yongmin Liu,Yun Raymond Fu
https://www.khoury.northeastern.edu/research_projects/multi-disciplinary-preparation-of-next-generation-information-assurance-practitioners/,"Northeastern University, designated as a Center of Academic Excellence in Information Assurance Education and Research, has produced twenty SFS students over the past three years, all of whom were placed in positions within the Federal Government and Federally Funded Research and Development Centers. The program's unique diversity includes students from backgrounds ranging from political science and criminal justice to computer science and engineering. Northeastern University is well-positioned to attract and educate strong students in cybersecurity through its nationally-recognized Cooperative Education program. The SFS program at Northeastern successfully recruits a diverse group of underrepresented students and is committed to sustaining this level of diversity in future recruiting. Northeastern University also reaches out to the broader community by leading Capture-the-Flag and Collegiate Cyber Defense competitions, and by actively participating in the New England Advanced Cyber Security Center, an organization composed of academia, industry, and government entities.",,David Kaeli
https://www.khoury.northeastern.edu/research_projects/msstats-and-cardinal-next-generation-statistical-mass-spectrometry-in-r/,"MSstats is a family of open-source R/Bioconductor packages for statistical relative quantification of peptides and proteins in mass spectrometry-based proteomics. MSstats takes as input a list of identified and quantified spectral features and supports arbitrary complex designs (factorial experiments, paired designs, time course), data acquired with shotgun DDA, data independent DIA/SWATH, PRM or targeted SRM workflows, and label-free or label-based (e.g., TMT labeling) workflows.

Cardinal is a family of open source R/Bioconductor packages for statistical analysis of mass spectrometry-based imaging (MSI) experiments of biological samples. Cardinal supports 2- and 3-dimensional MSI experiments with multiple tissues and conditions, and complex designs, as well as matrix-assisted laser desorption/ionization and desorption electrospray ionization-based workflows.",Olga Vitek,Kylie Ariel Bemis
https://www.khoury.northeastern.edu/research_projects/mobots/,"Robust activity recognition algorithms depend on how well their training datasets have been prepared. An important part of preparing this training data set is to have high-quality annotations/labels on the entire dataset. However, if the dataset gets bigger and bigger, adding annotations to it becomes even more cumbersome for the research team. Often, these tasks are done manually on small datasets by researchers. In order to solve this computational problem, we have designed “Mobots” – a human-computation (i.e. crowdsourcing) game to annotate large accelerometer datasets (e.g., NHANES and UK BioBank datasets). In Mobots, players are shown snippets of accelerometer data that they match with a lab-based ground truth data (as shown below). This way, we can gather annotations on a very large dataset with the quality of lab-based ground truth.",Stephen Intille,Seth Cooper
https://www.khoury.northeastern.edu/research_projects/mobilyzer/,"Despite over a decade of Internet access from smartphones, we still have little understanding of the network performance we receive. A number of small testbeds and user studies have enabled progress in the face of these challenges, but with limited scope, duration, coverage and generality. This previous work suffers from three key limitations that hamper their success.
First, these individual solutions do not scale: each individual app or measurement platform is inherently limited to the population of participating users running a single piece of software.
Second, each solution is inconsistent and inflexible in the set of network measurements it supports and the contextual information describing the experimental environment, making it difficult to ensure scientific rigor and to merge disparate datasets.
Third, these solutions are uncoordinated in how they conduct network measurements: multiple apps can wastefully measure the same property independently or, worse, interfere with each other by running measurements at the same time from the same device.
Mobilyzer addresses these issues by providing a scalable, efficient and controllable open platform for network measurement from mobile devices. Mobilyzer provides the following components:
Mobile measurement library for apps. An app-based deployment model is uniquely capable of capturing the detailed view of mobile systems described above. Our Mobilyzer library provides standard measurement tools for users, researchers and developers, and it manages data collection by reporting to cloud-based servers.
Measurement manager. Mobilyzer allows researchers to conduct mobile network experiments using a collection of mobile devices running apps. To support a wide range of existing and future experiments, the measurement manager can assign programmable collections of measurements to devices in a way that optimizes for efficient use of the available, limited resources. In addition to scheduling measurements, this system coordinates across multiple devices to ensure that measurements do not overwhelm any particular device, network or host being probed.
Data collection, analysis and archival. We use a cloud-based system to collect, analyze, anonymize and publish data reported from mobile devices. This approach simplifies data management and sharing, provides a centralized repository for tools that analyze the data and facilitates access to a collection of hosts with sufficient capacity to perform the analysis in situ.
Mobilyzer is a collaboration between Morley Mao’s group at the University of Michigan and David Choffnes’ group at Northeastern University. For more information, please visit the project page.","Z. Morley Mao, David Choffnes",David Choffnes
https://www.khoury.northeastern.edu/research_projects/mixwild/,"Mix-WILD (“Mixed model analysis With Intensive Longitudinal Data”) is a desktop application for multilevel modeling of behavior using EMA data. It provides a graphical user interface to manipulate missing value codes, configure model parameters, and test random intercepts and slopes as predictors, mediators, and moderators of outcome variables in intensive longitudinal data. Mix-WILD allows behavioral researchers to extend the stage 1 regressor model with random slopes, feed random slopes into stage 2 models, and save output files in desired formats.",Donald Hedeker,Donald Hedeker
https://www.khoury.northeastern.edu/research_projects/microinteraction-ecological-momentary-assessment/,"Ecological momentary assessment (EMA) is a data collection methodology where a user's smartphone prompts them with multiple-choice questions related to a research construct of interest several times a day. EMA is used to measure behaviors such as mood, eating habits, and current physical activity. However, EMA often induces high study burden on the participants resulting in lower compliance/response rates. Low response rates affect the measurement of behavior, thereby affecting the quality of behavioral data.

μEMA (micro-EMA), or microinteractions-based ecological momentary assessment, is an alternative approach to EMA. In μEMA, all the prompts are single questions with Yes/No kind of answers – responding to each of these questions is a single-tap quick glanceable “microinteraction” (like checking the time on a wristwatch), taking hardly ~ 2s. μEMA leverages the quick access time and reliable tactile vibrations on the smartwatches to deliver short self-report surveys at a high temporal density (like a sensor).",Stephen Intille,Aditya Ponnada
https://www.khoury.northeastern.edu/research_projects/measuring-and-improving-the-management-of-todays-pki/,"The Public Key Infrastructure (PKI), along with the Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols, are responsible for securing Internet transactions such as banking, email, and e-commerce; they provide users with the ability to verify with whom they are communicating online, and enable encryption of those communications. While the use of the PKI is mostly automated, there is a surprising amount of human intervention in management tasks that are crucial to its proper operation. As a result, there have been numerous instances where mismanagement of the PKI has harmed the security of end users. This project is developing techniques to better understand and improve the management of the PKI, helping to better secure the Internet.

This project has four research foci, each examining the management challenges faced by different players in the PKI: Content Distribution Network (CDN) administrators, Certificate Authorities (CAs), end-users, and non-Web protocols. First, the project is conducting measurements to better understand the frequency of sharing private keys between sites and their CDNs, and to improve the security of this practice. Second, the project is developing new incentives for CAs to ensure information about their revoked certificates reach end users. Third, the project is aiming to better understand how the PKI will evolve as the Internet of Things (IoT) grows and the PKI is forced to quickly scale up. Fourth, the project will expand existing measurement approaches to understand the difficulties of PKI management in non-Web protocols (e.g., IMAPS), which have traditionally been less-well maintained.",Alan Mislove,David Choffnes
https://www.khoury.northeastern.edu/research_projects/machine-learning-approaches-towards-risk-assessment-and-prediction-of-adverse-pregnancy-outcomes/,"The research aims to comprehend the interplay between molecular, genetic, and clinical factors linked to adverse pregnancy outcomes (APOs), develop techniques for accurately assessing APO risk early on, and create methods for gathering additional clinical data during routine treatment of at-risk subjects. The team will use advanced machine learning and integrate clinical, genetic, and molecular data to achieve these objectives. Their strategies hold the potential to advance precision medicine in women's pregnancy and postpartum care. The project will primarily use data from the national ""Nulliparous Pregnancy Outcomes Study: monitoring mothers-to-be"" (nuMoM2b study). The 10,038 nulliparous women in the cohort will be used to complete three objectives: to integrate genetic, clinical, and molecular features to thoroughly understand APOs; to create advanced risk prediction machine learning models; and to actively gather data for risk assessment and model development. The researchers anticipate that this study will make substantial contributions to understanding APOs' molecular and clinical facets and assessing APO risk, ultimately improving maternal health through a close partnership between computational and clinical scientists.",David M. Haas,Predrag Radijovac
https://www.khoury.northeastern.edu/research_projects/ncs-fo-leveraging-deep-probabilistic-models-to-understand-the-neural-bases-of-subjective-experience/,Different individuals experience events differently due to their unique histories and psychological dispositions. This variation is known as subjective experience. It remains unclear how to model the neural bases of subjective experience. This work will develop new statistical modeling techniques for individual variation and apply them to a neuroimaging study of the fear experience. This will provide insights into the neural bases of fear and a framework to compare different hypotheses about the neural bases of individual differences.,Ajay Satpute,Jennifer Dy
https://www.khoury.northeastern.edu/research_projects/lava/,"Evaluating and improving bug-finding tools is currently difficult due to a shortage of ground truth corpora (i.e., software that has known bugs with triggering inputs). LAVA attempts to solve this problem by automatically injecting bugs into software. Every LAVA bug is accompanied by an input that triggers it whereas normal inputs are extremely unlikely to do so. These vulnerabilities are synthetic but, we argue, still realistic, in the sense that they are embedded deep within programs and are triggered by real inputs. Our work forms the basis of an approach for generating large ground-truth vulnerability corpora on demand, enabling rigorous tool evaluation and providing a high-quality target for tool developers.",Brendan Dolan-Gavitt,William Robertson
https://www.khoury.northeastern.edu/research_projects/language-and-runtime-support-for-large-scale-data-analytics/,"As the cost of computing and communication resources has plummeted, applications have become data-centric with data products growing explosively in both number and size. Although accessing such data using the compute power necessary for its analysis and processing is cheap and readily available via cloud computing (intuitive, utility-style access to vast resource pools), doing so currently requires significant expertise, experience, and time (for customization, configuration, deployment, etc).
This work investigates new models of cloud computing that combine domain-targeted languages with scalable data processing, sharing, and management abstractions within a distributed service platform that “scales” programmer productivity. To enable this, this research explores new programming language, runtime, and distributed systems techniques and technologies that integrate the R programming language environment with open source cloud platform-as-a-service (PaaS) in ways that simplify processing massive datasets, sharing datasets across applications and users, and tracking and enforcing data provenance. The PIs’ plans for research, outreach, integrated curricula, and open source release of research artifacts have the potential for making cloud computing more accessible to a much wider range of users: The data analytics community who use the R statistical analysis environment to apply their techniques and algorithms to important problems in areas such as biology, chemistry, physics, political science and finance, by enabling them to use cloud resources transparently for their analyses, and to share their scientific data/results in a way that enables others to reproduce and verify them.",Jan Vitek,Jan Vitek
https://www.khoury.northeastern.edu/research_projects/crisp-type-2-interdependent-network-based-quantification-of-infrastructure-resilience-inquire/,"Critical infrastructure systems are increasingly reliant on one another for their efficient operation. This research will develop a quantitative, predictive theory of network resilience that takes into account the interactions between built infrastructure networks, and the humans and neighborhoods that use them. This framework has the potential to guide city officials, utility operators, and public agencies in developing new strategies for infrastructure management and urban planning. More generally, these efforts will untangle the roles of network structure and network dynamics that enable interdependent systems to withstand, recover from, and adapt to perturbations. This research will be of interest to a variety of other fields, from ecology to cellular biology.",Albert-László Barabási,Edmund Yeh
https://www.khoury.northeastern.edu/research_projects/interactive-synthesis-and-repair-for-robot-programs/,"Over the past few years, robots have started to be deployed in unstructured human environments. There are hundreds of robots deployed in hospitals, hotels, and supermarkets. Unfortunately, the software that runs on robots is programmed using low-level abstractions and languages, and is hard to transfer across robots and environments. In addition robotic software requires complex control logic to ensure that robots are safe and well-behaved in all situations. Thus, robot software is extraordinarily hard to write and maintain. This research project develops tools and techniques to make robot software safer, easier to write, and easier to maintain.

The intellectual merits of the project are the development of (1) techniques for fixing bugs in robot software, based on advances to automatic program repair and program synthesis; (2) abstractions for writing robot software that can automatically handle certain kinds of failures, based on new programming-language design; (3) methods for checking the correctness of robot software, based on new program-verification techniques. The project’s broader significance and importance are that it helps make robot software easier to write and maintain, and cheaper, safer, and more reliable. The project encourages further research at the intersection of programming languages and robotics by publishing research results and releasing open-source software. The project also involves high-school outreach workshops to broaden participation in computing.",Arjun Guha,Arjun Guha
https://www.khoury.northeastern.edu/research_projects/insure-4-0-advancing-research-education-to-research-collaborative/,"We will expand the current INSuRE program to:

* Increase the availability of the INSuRE program to the general CAE-R and CAE-CD communities by recruiting researchers from various government agencies.
* Help to facilitate research collaborations between academic institutions and government agencies by offering a year-long INSURE-Collaborative program, including summer internships.",Agnes H. Chan,Agnes H. Chan
https://www.khoury.northeastern.edu/research_projects/human-centered-a-i-for-federal-governments/,We are designing human-centered artificial intelligence that governments can implement to provide better services and relationships to their citizens.,Saiph Savage,Saiph Savage
https://www.khoury.northeastern.edu/research_projects/ground-truth-analysis-and-modeling-of-entire-individual-c-elegans-nervous-system/,"The Boyden, Flavell, Barabasi, and Tegmark groups propose to examine how the cells within the brain of a simple animal work together to generate the computations that underlie behavior. The teams will study C. elegans, a small worm with just a few hundred neurons, yet capable of learning and adaptive behavior in complex real-world environments. The teams will apply new technologies to measure and control the neural circuits of C. elegans, in order to investigate how they works. The project will also generate new mathematical tools to analyze the data that is collected – tools that could help analyze how the brain goes wrong in disorders such as Parkinson’s or Alzheimer’s. Using the data acquired, the project will reveal how brain circuits compute, which could inspire new algorithms for machine learning and computer information processing. These in turn could have broad impact on economic prosperity as well as in advancing human quality of life.",Ed Boyden,Albert-László Barabási
https://www.khoury.northeastern.edu/research_projects/shf-large-gradual-typing-across-the-spectrum/,"This project aims to address the challenges of maintaining software systems written in scripting languages. Despite their ease of prototyping, scripting languages lack sound types, making it difficult to understand and modify code. The researchers propose to develop gradual typing systems that allow programmers to incrementally add type annotations to existing code, preserving the advantages of scripting frameworks while enhancing maintainability. They will compare and evaluate existing gradual typing approaches, develop an evaluation framework, and explore new scripting languages that incorporate these insights. This research is expected to improve the maintainability of scripting language-based software, assist programmers in fixing bugs and improving performance, and advance the understanding of gradual typing.",Matthias Felleisen,Jan Vitek
https://www.khoury.northeastern.edu/research_projects/geopolitical-routing/,"Internet users seeking privacy and anonymity, such as whistleblowers and dissidents, require secure communication methods. Existing anonymity services like Tor offer protection, but are vulnerable to traffic analysis. This research aims to design, implement, and deploy anonymous communication networks that prevent eavesdropping by even powerful adversaries like state actors. The project proposes anonymity network designs that leverage a combination of trusted infrastructure and untrusted P2P nodes, incorporate zones for jurisdictional trust selection, and optimize performance based on communication workload observations. The goal is to develop networks that provide anonymity guarantees for file sharing, web traffic, and real-time communication in both fixed-line and mobile environments, even under strong adversarial scenarios. This project is a collaboration with the Boston University Security Group and is funded by the NSF.",David Choffnes,Sharon Goldberg
https://www.khoury.northeastern.edu/research_projects/game-theoretic-updates-for-network-and-cloud-functions/,"Updates are common in cloud-computing networks and must be efficient and transparent since they can take seconds or minutes to complete, and cloud-computing networks must be ""always on."" This project investigates key shortcomings of prior work on update abstractions that limit their utility and widespread use in practice, and develops a new abstraction that addresses the heterogeneity, scale, and dynamic nature of real-world updates. The project's novelties are (1) a new game-theoretic foundation for network updates, (2) algorithms for synthesizing update controllers that are robust to failures and changing conditions during the update, (3) algorithms for explaining update failures, (4) a language design that allows synthesized controllers to be safely modified, and (5) implementations and evaluations of these mechanisms for virtual network functions and serverless-computing platforms. The project provides network operators with tools that make updates to networked systems easier, safer, and more reliable, and develops a framework that makes datacenter computing more reliable and secure.",Arjun Guha,Arjun Guha
https://www.khoury.northeastern.edu/research_projects/foundations-of-just-in-time-compilation/,"Modern programming languages rely on just-in-time compilation techniques to achieve performance competitive with computer languages such as C or C++. Just-in-time compilers can observe the program’s actions as it executes, and inspect its state. Knowledge of the program’s state and past behavior, allows the compiler to perform speculative optimizations that improve performance. This project develops a general model of just-in-time compilation that subsumes deployed systems and allows systematic exploration of the design space of dynamic compilation techniques. The research questions that will be tackled in this work lie along two dimensions: Experimental—explore the design space of dynamic compilation techniques and gain an understanding of trade-offs; Foundational—formalize key ingredients of a dynamic compiler and develop techniques for reasoning about correctness in a modular fashion.",Jan Vitek,Amal Ahmed
https://www.khoury.northeastern.edu/research_projects/foundations-for-gradual-typing/,,Amal Ahmed,
https://www.khoury.northeastern.edu/research_projects/foodome-connecting-polyphenols-to-health/,The Foodome project aims to develop a systematic approach to analyzing lifestyle factors contributing to coronary heart disease (CHD). The goal is to create tools and a computational framework to accurately detect the relationship between diet and CHD.,,Albert-László Barabási
https://www.khoury.northeastern.edu/research_projects/enhancement-and-support-of-dmtcp-for-adaptive-extensible-checkpoint-restart/,"Society’s increasingly complex cyberinfrastructure creates a concern for software robustness and reliability. Yet, this same complex infrastructure is threatening the continued use of fault tolerance. Consider when a single application or hardware device crashes. Today, in order to resume that application from the point where it crashed, one must also consider the complex subsystem to which it belongs. While in the past, many developers would write application-specific code to support fault tolerance for a single application, this strategy is no longer feasible when restarting the many inter-connected applications of a complex subsystem.
This project will support a plugin architecture for transparent checkpoint-restart. Transparency implies that the software developer does not need to write any application-specific code. The plugin architecture implies that each software developer writes the necessary plugins only once. Each plugin takes responsibility for resuming any interrupted sessions for just one particular component. At a higher level, the checkpoint-restart system employs an ensemble of autonomous plugins operating on all of the applications of a complex subsystem, without any need for application-specific code.
The plugin architecture is part of a more general approach called process virtualization, in which all subsystems external to a process are virtualized. It will be built on top of the DMTCP checkpoint-restart system. One simple example of process virtualization is virtualization of ids. A plugin maintains a virtualization table and arranges for the application code of the process to see only virtual ids, while the outside world sees the real id. Any system calls and library calls using this real id are extended to translate between real and virtual id. On restart, the real ids are updated with the latest value, and the process memory remains unmodified, since it contains only virtual ids. Other techniques employing process virtualization include shadow device drivers, record-replay logs, and protocol virtualization. Some targets of the research include transparent checkpoint-restart support for the InfiniBand network, for programmable GPUs (including shaders), for networks of virtual machines, for big data systems such as Hadoop, and for mobile computing platforms such as Android.",Gene Cooperman,Gene Cooperman
https://www.khoury.northeastern.edu/research_projects/cdi-type-iii-collaborative-research-dynamical-processes-in-interdependent-techno-social-networks/,"This multidisciplinary, data-driven research project will:

* Study the microscopic processes that rule the dynamics of interdependent networks, with a particular focus on the social component.
* Define new mathematical models/foundational theories for the analysis of the robustness/resilience and contagion/diffusive dynamics of interdependent networks.",David Lazer,Alessandro Vespignani
https://www.khoury.northeastern.edu/research_projects/development-of-algorithms-for-detecting-the-activities-of-adults-and-children-from-wearable-sensors/,"We are working on a variety of projects studying how to use mobile sensor data, especially from accelerometers, to detect physical activity (type, duration, and intensity), sedentary behavior, and sleep in adults and children. We are interested in extending this work to detect habits, and ultimately to develop a comprehensive probabilistic model of someone’s behaviors.",Stephen Intille,Stephen Intille
https://www.khoury.northeastern.edu/research_projects/crowd-sourced-annotation-of-longitudinal-sensor-data-to-enhance-data-driven-precision-medicine-for-behavioral-health/,"Longitudinal sensor data from wearable monitors and mobile devices offers the potential to transform behavioral science. However, this data often lacks the rich annotations necessary for scientific analysis. To address this issue, we explored the use of mobile application game players to provide additional annotations, enhancing the data for behavioral science and enabling automatic processing. This approach has the potential to improve the understanding of how individual-level behaviors relate to health outcomes in research studies like NHANES and All of Us.",Stephen Intille,Seth Cooper
https://www.khoury.northeastern.edu/research_projects/conversational-agents-to-improve-quality-of-life-in-palliative-care/,,Timothy W. Bickmore,Michael K. Paasche-Orlow
https://www.khoury.northeastern.edu/research_projects/fmitf-track-i-advert-compositional-atomic-specifications-for-distributed-system-verification/,"Distributed systems are difficult to verify due to their inherent complexity from handling concurrency and network asynchrony. This project's novelties are a compositional atomic distributed object model that facilitates reasoning and verification of both individual and composition of distributed systems, and a formal verification tool, ADVERT, that can be used to build large-scale certified distributed systems. The project's impacts include new tools to significantly improve the reliability and security of large-scale software infrastructures, such as the cloud, and applications that run on top of the infrastructure, and also new courses on distributed-system design and verification that will broaden the participation of underrepresented groups.",Zhong Shao,Robert Soule
https://www.khoury.northeastern.edu/research_projects/shf-small-collaborative-research-compiler-coaching/,"The ""Compiler Coaching"" (Dialog) project explores creating communication channels between translation processes and software engineers to improve software speed, size, or energy consumption. It involves optimizing compilers for Racket and JavaScript languages, establishing communication channels, and gathering empirical evidence on their benefits for software engineers. The project aims to enable programming language developers to implement similar channels for their clients and contribute to an open-source programming language project with a history of educational outreach.",Matthias Felleisen,Matthias Felleisen
https://www.khoury.northeastern.edu/research_projects/collecting-family-health-history-using-relational-agents/,"A family health history can significantly improve disease risk assessments. However, most health providers do a poor job of collecting this information. This project aims to develop a relational agent that simulates the behavior of a genetics counselor to collect family health histories from individuals by interviewing them about their family. Preliminary testing has shown that patients find the agent significantly easier to use compared with a conventional web-based tool. This work is a collaboration with Dr. Catharine Wang at the Boston University School of Public Health and Dr. Michael Paasche-Orlow at the Boston Medical Center.",Timothy W. Bickmore,Timothy W. Bickmore
https://www.khoury.northeastern.edu/research_projects/center-for-statistics-and-quantitative-infectious-diseases/,"The Center for Statistics and Quantitative Infectious Diseases (CSQUID) is a multi-institutional MIDAS Center of Excellence with a multi-disciplinary approach to computational, statistical, and mathematical modeling of important infectious diseases. Research is motivated by multi-scale problems such as immunologic, epidemiologic, and environmental drivers of the spread of infectious diseases with the goal of understanding and communicating the implications for public health policy.

To extend the results of the MIDAS Center’s research projects beyond academia, the Software Development team, led by Northeastern professor Alessandro Vespignani, will help translate the research into products that can be used by external researchers and public health officials. To do so, the team will integrate some of the independently developed tools to create a coherent computational infrastructure that is more than the sum of its methodological parts. In particular, the Software Development team will develop and maintain a suite of computational tools for infectious disease modeling and analysis centered around a multi-scale modeling computational platform (MCP), optimized for cloud deployment.

The major aims of these software developments are:
* Develop an MCP capable of integrating large scale stochastic modeling approaches working at different scales of resolution. We will start by creating a multi-scale hybrid model based on combining the global individual-based meta-population model GLEAM with the US scale agent-based influenza model FluTE. The MCP architecture will be designed around the existing GLEAMviz client-server architecture. It will be expanded with the development of Application Programming Interfaces (APIs) for the plug-in of models developed by the MIDAS research community. The MCP will consist of computationally intensive tools, so we plan to design and to deploy a cloud computing environment with elastic capabilities.

* Develop new features and graphical user interfaces (GUIs) for statistical tools developed in the context of the research activities of the Center such as extensions of pomp, TranStat, among others. We will develop integrated workflows aimed at allowing those programs to exchange data and parameter estimates with the MCP in an automated way.

* Develop a website that will act as a sharing repository for the software developed in this MIDAS Center, with training materials, manuals, and workflow examples. We aim to provide the best accessibility and to foster adoption of the developed software by MIDAS, the research community, and public health agencies by using best practices and public repositories.",Alessandro Vespignani,Alessandro Vespignani
https://www.khoury.northeastern.edu/research_projects/satc-core-medium-collaborative-bridging-the-gap-between-protocol-design-and-implementation-through-automated-mapping/,"Computer networking and the internet have revolutionized our societies, but are plagued with security problems which are difficult to tame. Serious vulnerabilities are constantly being discovered in network protocols that affect the work and lives of millions. Even some protocols that have been carefully scrutinized by their designers and by the computer engineering community have been shown to be vulnerable afterwards. Why is developing secure protocols so hard? This project seeks to address this question by developing novel design and implementation methods for network protocols that allow to identify and fix security vulnerabilities semi-automatically. The project serves the national interest as cyber-security costs the United States many billions of dollars annually. Besides making technical advances to the field, this project will also have broader impacts in education and curriculum development, as well as in helping to bridge the gap between several somewhat fragmented scientific communities working on the problem.
Technically, the project will follow a formal approach building upon a novel combination of techniques from security modeling, automated software synthesis, and program analysis to bridge the gap between an abstract protocol design and a low-level implementation. In particular, the methodology of the project will be based on a new formal behavioral model of software that explicitly captures how the choice of a mapping from a protocol design onto an implementation platform may result in different security vulnerabilities. Building on this model, this project will provide (1) a modeling approach that cleanly separates the descriptions of an abstract design from a concrete platform, and allows the platform to be modeled just once and reused, (2) a synthesis tool that will automatically construct a secure mapping from the abstract protocol to the appropriate choice of platform features, and (3) a program analysis tool that leverages platform-specific information to check that an implementation satisfies a desired property of the protocol. In addition, the project will develop a library of reusable platform models, and demonstrate the effectiveness of the methodology in a series of case studies.",Stavros Tripakis,Cristina Nita-Rotaru
https://www.khoury.northeastern.edu/research_projects/behaviot-modeling-and-controlling-internet-of-things-behavior-using-network-inferred-state-machines/,"This project aims to investigate how to automatically determine when IoT systems compromise privacy, security, and correctness, as well as mitigate such problems. The key idea is to focus on information gleaned from the network traffic that such devices generate, since network traffic is the common platform that all such IoT systems ultimately rely upon. Specifically, the project will develop technology that models the behavior of an IoT system from its network traffic, then use these models to identify unexpected behavior. To mitigate unexpected behavior, the project will identify in-network strategies such as isolating, changing, and/or blocking such traffic.",David Choffnes,David Choffnes
https://www.khoury.northeastern.edu/research_projects/twc-medium-automating-countermeasures-and-security-evaluation-against-software-side-channel-attacks/,"Side-channel attacks (SCA) exploit information leakage from cryptographic implementations to recover secret keys. While effective countermeasures exist, they are application-specific and labor intensive. This project proposes an automation framework for information leakage analysis, multi-level countermeasure application, and formal security evaluation against software side-channel attacks. The framework unifies power analysis and cache-based timing attacks, defines new metrics of information leakage, and automatically identifies possible leakage. It extends the compilation process to optimize for security and ensure secure execution at run-time. Formal methods guarantee side-channel security at a certain confidence level. The outcome benefits security system architects and software developers in building verifiable SCA security into their applications. The project engages undergraduates, women, and minority students in research and develops new educational tools.",Yunsi Fei,Aidong Ding
https://www.khoury.northeastern.edu/research_projects/twc-medium-collaborative-automated-reverse-engineering-of-commodity-software/,"Software, including common examples such as commercial applications or embedded device firmware, is often delivered as closed-source binaries. While prior academic work has examined how to automatically discover vulnerabilities in binary software, and even how to automatically craft exploits for these vulnerabilities, the ability to answer basic security-relevant questions about closed-source software remains elusive. This project aims to provide algorithms and tools for answering these questions. Leveraging prior work on emulator-based dynamic analyses, we propose techniques for scaling this high-fidelity analysis to capture and extract whole-system behavior in the context of embedded device firmware and closed-source applications. Using a combination of dynamic execution traces collected from this analysis platform and binary code analysis techniques, we propose techniques for automated structural analysis of binary program artifacts, decomposing system and user-level programs into logical modules through inference of high-level semantic behavior. This decomposition provides as output an automatically learned description of the interfaces and information flows between each module at a sub-program granularity. Specific activities include: (a) developing software-guided whole-system emulator for supporting sophisticated dynamic analyses for real embedded systems; (b) developing advanced, automated techniques for structurally decomposing closed-source software into its constituent modules; (c) developing automated techniques for producing high-level summaries of whole system executions and software components; and (d) developing techniques for automating the reverse engineering and fuzz testing of encrypted network protocols. The research proposed herein will have a significant impact outside of the security research community. We will incorporate the research findings of our program into our undergraduate and graduate teaching curricula, as well as in extracurricular educational efforts such as Capture-the-Flag that have broad outreach in the greater Boston and Atlanta metropolitan areas. The close ties to industry that the collective PIs possess will facilitate transitioning the research into practical defensive tools that can be deployed into real-world systems and networks.",Engin Kirda,William Robertson
https://www.khoury.northeastern.edu/research_projects/auditory-seasoning/,"The experience of what we eat depends not only on taste, but also on other sensory feedback. Perceptual research has shown the potential of altering visual, olfactory, or textural food cues to affect flavor, texture, and satiety. Recently, the HCI community has leveraged such research to encourage healthy eating, but the resulting tools often require invasive or additional devices. Ubiquitous and unobtrusive, audio feedback-based tools could alleviate those drawbacks, but research in this area has been limited to food texture. We expand on prior psychology research by exploring a wide range of auditory feedback styles to modify not only flavor attributes but also appetite-related measures. We have developed mobile tools that offer curated audio modes to alter chewing sounds to significantly influence food perception and eating behavior beyond texture alone.",Rebecca Kleinberger,Rebecca Kleinberger
https://www.khoury.northeastern.edu/research_projects/auditing-critical-dependencies-between-online-media-platforms/,"This research aims to audit the dependencies between major online media platforms, with a focus on major search engines, and investigate the extent to which they rely on content from social media platforms. It will answer questions about the fraction of search results linking to social media, the social media platforms and authors appearing in search results, how links to social media vary by query, whether results for social media are personalized, and whether these links increase content diversity or serve as vehicles for misinformation. By conducting hybrid algorithm audits that combine real-user experiments with simulated online identities, the research will address the challenge of ecological validity by using a dataset of Google Search queries from a large participant panel and leveraging autocomplete suggestions to diversify queries. The results aim to enhance public media literacy and inform the designers of the platforms.",Christo Wilson,Christo Wilson
https://www.khoury.northeastern.edu/research_projects/assessing-and-communicating-movement-stereotypy-and-arousal-telemetrically-in-individuals-with-autism-spectrum-disorder/,"Stereotypical motor movements (stereotypies) are common in individuals with Autism Spectrum Disorder (ASD). Evidence suggests that stereotypies may be related to arousal regulation, with changes in autonomic activity preceding or following stereotypies. This project aimed to explore this relationship using ambulatory heart rate monitors and wireless motion sensors. The goal was to develop more accurate and reliable methods for detecting and assessing stereotypies in real-time, allowing for better understanding and intervention.",Matthew Goodwin,Matthew Goodwin
https://www.khoury.northeastern.edu/research_projects/aqua-and-other-privacy-enhancing-systems/,Aqua project page,Stevens Le Blond,Stevens Le Blond
https://www.khoury.northeastern.edu/research_projects/anyone-python/,"Anyone Python is an online “Basic Python” class using Zoom for ALL (students and parents). In this online class, students learn ‘Basic Python’ and ‘Intro Computer Science’ in an informal way. No curriculum, No textbook, No grade, No PPT files, No materials, No stress … just a computer.
Anyone Python most recently finished its third season on March 19, 2021. A total 150 people from all over the world (US, South Korea and China) registered for the third season, comprising of 10 episodes conducted every week over Zoom. The main theme of Season 03 was “Core Python”, allowing students to learn more about core Python and computer science in general.
All Anyone Python episodes are available as Youtube videos. All materials are available at description of each Youtube video. For more information, please visit the Anyone Python homepage.",Jeongkyu Lee,Jeongkyu Lee
https://www.khoury.northeastern.edu/research_projects/a-i-to-empower-displaced-rural-workers/,"**Abstract:**

The research project aims to empower displaced rural workers by developing methods for transitioning them into high-skilled digital jobs that are unlikely to be automated. It explores how to leverage Artificial Intelligence (AI) tools to augment workers' abilities rather than displace them, and how to design tools that foster skill development and creativity. The project investigates how to support marginalized workers in their transition to online work, addressing the challenge that they often lack the time or resources for unpaid training. It seeks to understand worker skills and trajectories, develop new human-computer interaction paradigms to enable collaboration with AI, and explore organizational structures that support skill development and creativity. By grounding the research in real-world contexts, the project aims to lay a foundation for future research on the intersection of human workers and AI in online work.",Saiph Savage,Saiph Savage
https://www.khoury.northeastern.edu/research_projects/a-language-based-approach-to-faster-and-safer-serverless-computing/,"Cloud computing, which allows a customer to rent virtual servers from cloud providers, is the infrastructure that powers a wide variety of Internet applications used by consumers, businesses, and the government. Unfortunately, traditional cloud computing requires significant system-management expertise to ensure that applications are reliable, secure, and cost-effective. In contrast, “serverless computing” is a new approach to cloud computing that automates a significant portion of system management, and has seen explosive growth over the last few years. Despite being a promising advance, serverless computing introduces new problems, and is more limited in scope than traditional cloud computing. This research project develops tools and techniques to make serverless computing more cost-effective, more reliable, and more broadly applicable.
The intellectual merits of the project are the development of (1) the mathematical foundations of serverless computing, (2) analysis tools to help programmers find and eliminate software bugs in serverless software, (3) new abstractions that enable a broader class of software to use serverless computing, and (4) new runtime systems that make serverless computing faster and cheaper. The project’s broader significance and importance are that (1) it helps programmers make their serverless applications more reliable and secure, (2) it benefits cloud-computing providers by making serverless computing cheaper and faster, and (3) it encourages further research in this new area by enabling the publishing of research results and the release of open-source software. The project also involves high-school outreach workshops to broaden participation in computing.",Arjun Guha,Arjun Guha
